import os
import streamlit as st
from dotenv import load_dotenv
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings
from langchain.text_splitter import CharacterTextSplitter
from langchain.document_loaders import TextLoader
from langchain.chains.question_answering import load_qa_chain
from langchain_openai import ChatOpenAI

load_dotenv()
openai_api_key = os.getenv("OPENAI_API_KEY")

# ãƒ™ã‚¯ãƒˆãƒ«ä¿å­˜ãƒ•ã‚¡ã‚¤ãƒ«å
VECTORSTORE_PATH = "faiss_index"

# ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã®å†åˆ©ç”¨ or ä½œæˆ
def load_vectorstore():
    if os.path.exists(VECTORSTORE_PATH):
        # allow_dangerous_deserialization=True ã‚’è¿½åŠ 
        return FAISS.load_local(VECTORSTORE_PATH, OpenAIEmbeddings(openai_api_key=openai_api_key), allow_dangerous_deserialization=True)
    else:
        loader = TextLoader("docs/knowledge.txt", encoding="utf-8")
        docs = loader.load()
        text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
        docs_split = text_splitter.split_documents(docs)
        embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)
        vectorstore = FAISS.from_documents(docs_split, embeddings)
        vectorstore.save_local(VECTORSTORE_PATH)
        return vectorstore

# Streamlit UI
st.title("ğŸ“„ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ")
query = st.text_input("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„:")

if query:
    vectorstore = load_vectorstore()
    docs = vectorstore.similarity_search(query)
    llm = ChatOpenAI(openai_api_key=openai_api_key)
    chain = load_qa_chain(llm, chain_type="stuff")
    response = chain.run(input_documents=docs, question=query)
    st.write("ğŸ§  å›ç­”:")
    st.write(response)
